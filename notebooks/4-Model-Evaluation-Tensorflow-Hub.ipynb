{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('2.0.0-beta1', '0.5.0')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "tf.__version__, hub.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/human_label.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(index=str, columns={\"Human Label\": \"label\"}, inplace=True)\n",
    "df.rename(index=str, columns={\"cleansed_comment\": \"text\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.label != 'Neutral'] # filter out Neutral, it is not in our model\n",
    "df.label = df.label.apply(lambda x: 1 if x == 'Positive' else 0)\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_models = {}\n",
    "all_models['gnews_swivel'] = tf.keras.models.load_model('../models/gnews_swivel_1_ep_model.h5',\n",
    "                                                        custom_objects={ 'KerasLayer': hub.KerasLayer })\n",
    "all_models['nnlm_en_50'] = tf.keras.models.load_model('../models/nnlm_en_50_1_ep_model.h5',\n",
    "                                                      custom_objects={ 'KerasLayer': hub.KerasLayer })\n",
    "all_models['nnlm_en_128'] = tf.keras.models.load_model('../models/nnlm_en_128_1_ep_model.h5',\n",
    "                                                       custom_objects={ 'KerasLayer': hub.KerasLayer })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = {\n",
    "    'model_name': [],\n",
    "    'accuracy': [],\n",
    "    'precision': [],\n",
    "    'recall': [],\n",
    "    'f1_score': [],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, model in all_models.items():\n",
    "    yhat_probs = model.predict(df.text.values)[:, 0]\n",
    "    yhat_classes = model.predict_classes(df.text.values)[:, 0]\n",
    "    accuracy = accuracy_score(df.label.values, yhat_classes)\n",
    "    precision = precision_score(df.label.values, yhat_classes)\n",
    "    recall = recall_score(df.label.values, yhat_classes)\n",
    "    f1 = f1_score(df.label.values, yhat_classes)\n",
    "    \n",
    "    metrics['model_name'].append(name)\n",
    "    metrics['accuracy'].append(accuracy)\n",
    "    metrics['precision'].append(precision)\n",
    "    metrics['recall'].append(recall)\n",
    "    metrics['f1_score'].append(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gnews_swivel</td>\n",
       "      <td>0.929351</td>\n",
       "      <td>0.928251</td>\n",
       "      <td>0.841463</td>\n",
       "      <td>0.882729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nnlm_en_50</td>\n",
       "      <td>0.956969</td>\n",
       "      <td>0.956989</td>\n",
       "      <td>0.904472</td>\n",
       "      <td>0.929990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nnlm_en_128</td>\n",
       "      <td>0.959538</td>\n",
       "      <td>0.938650</td>\n",
       "      <td>0.932927</td>\n",
       "      <td>0.935780</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     model_name  accuracy  precision    recall  f1_score\n",
       "0  gnews_swivel  0.929351   0.928251  0.841463  0.882729\n",
       "1    nnlm_en_50  0.956969   0.956989  0.904472  0.929990\n",
       "2   nnlm_en_128  0.959538   0.938650  0.932927  0.935780"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "met = pd.DataFrame.from_dict(metrics)\n",
    "met"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
